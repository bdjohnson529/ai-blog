---
layout: post
title: "China and Open Source"
date: 2025-07-23 10:00:00 -0500
author: "Ben Johnson"
math: true
toc: true
reading_time: "15 min @ 250 wpm"
references:
---

China and the US are competing to lead AI development over the next 5 years. While both countries are investing significant capital into R&D, different incentive structures may give one country an unfair advantage.

The majority of investment comes from big tech companies in both countries. US cloud providers and tech companies are investing upwards $336B in FY2025. Chinese counterparts are investing less than â…“ of that amount in FY2025. The majority of this spend is AI infrastructure including data centers, chips and hardware.

## Big Tech Investments

{% include capex.html %}

Outside of big tech, there is also a significant difference in venture funding for startups. Considering only the top-funded startups, the US venture ecosystem is investing an order of magnitude more in startups such as OpenAI and Anthropic.

## Venture Investments

{% include venture.html %}

Investment by big tech does not tell the complete story. The Chinese government is also investing `$56B` into AI in FY2025, whereas the US government is only investing `$8.6B`, more than half of which comes from the Department of Defense. Public investment in China is significantly outpacing investment by the US federal government. This is to be expected as US investment is typically led by private markets, whereas China has a higher proportion of funding coming from public funds.

One additional piece to consider is the difference in access to hardware and chips. China is facing a supply chain shortage due to export restrictions on AI supply chain (NVIDIA, ASML and TSMC). Chinese AI companies are facing smaller investment, and limited access to AI infrastructure resources. This has some immediate effects on AI innovation - ByteDance mentioned that they were delayed by 3 months because they had to migrate from NVIDIA graphics cards to the Huawei equivalent.

## Open Source

One way that Chinese software companies are competing with US companies with deep pockets is using open-source. This means that smaller companies with less investment, such as DeepSeek, can compete with larger well-capitalized companies because they are able to leverage open-source models.

The majority of US AI companies are no longer open-source. This means they are not publishing their model weights, but equally importantly, they are not publishing research to share with the community. This means that the investment required to produce a new model is greater because researchers cannot take advantage of innovations across the market.

Meta is the largest company which is still publishing open-source models (LLaMa). Meta has a history of open-sourcing technology, and to this point it has worked out in their benefit. React, Pytorch and the Open Compute Project were all open sourced and each of them benefitted Meta.

The Open Compute Project is a great example - Meta published an open source version of their data centers. This added value because Meta established themselves as the market leader in data center design and established supply chains around their design, which lowered the cost of building data centers.

React and Pytorch are examples of other open source frameworks which were created by Meta. React improved the unit economics of producing software internally, which improved the development velocity within Meta. React also allowed Meta to attract and retain top engineering talent because they were building the bleeding-edge framework adopted by the rest of the market.

## LLaMa

In 2024, Mark published his open-source strategy for LLMs, centered around five premises:

1. Fine-tuning is necessary for real world applications
2. Vendor lock in is a business risk for customers
3. Data privacy is critical
4. Open source models will be cheaper
5. Open source ecosystem will enable monetization

A year later and many of these premises have been called into question.

1. **Fine-tuning may not be necessary** as general models are showing transferrable reasoning capabilities
2. **Customers are not overly concerned with vendor lock-in**, since model providers have adopted a standardized API interface which reduces the switching cost to close to zero.
3. **Data privacy does not seem to be limiting investment by customers.** Model companies sell packages which prevent pre-training on their datasets.

The two assumptions which may remain true are:

<ol start="4">
  <li>Open source models have remained cheaper</li>
  <li>Open source ecosystem can empower monetization, but this still remains to be shown</li>
</ol>

Open-source models have also proven difficult to monetize, which is to be expected. Meta is clearly pursuing alternative strategies to bring their AI models to market. The high CAPEX costs to train a model make it difficult to open-source, as opposed to PyTorch or another framework, training each model costs $10M or more.

## Future of Open Source

While Meta is considering how to improve their monetization, thinking about the broader ecosystem it is worth considering the consequences if Meta were to stop developing a frontier model which is open source.